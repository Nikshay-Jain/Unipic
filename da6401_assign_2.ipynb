{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30839,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9vm_nKgeITL",
        "outputId": "38f555b6-e493-425a-dd1c-85e39e4d3239"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time\n",
        "\n",
        "import itertools\n",
        "from os.path import basename\n",
        "\n",
        "import shutil\n",
        "import time\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import mobilenet_v3_small\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import DBSCAN"
      ],
      "metadata": {
        "id": "zigT_NM7hgSy"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir = r\"/content/drive/MyDrive/pics\""
      ],
      "metadata": {
        "id": "BKeg2ivWeNK1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_cluster_similarities(image_paths, labels, embeddings):\n",
        "    label_to_indices = {}\n",
        "    for idx, label in enumerate(labels):\n",
        "        if label == -1:\n",
        "            continue  # Skip noise\n",
        "        label_to_indices.setdefault(label, []).append(idx)\n",
        "\n",
        "    for label, indices in label_to_indices.items():\n",
        "        if len(indices) < 2:\n",
        "            continue  # Skip singleton clusters\n",
        "\n",
        "        print(f\"\\nCluster {label+1} — {len(indices)} images\")\n",
        "        for i, j in itertools.combinations(indices, 2):\n",
        "            emb_i, emb_j = embeddings[i], embeddings[j]\n",
        "            sim = np.dot(emb_i, emb_j)  # cosine similarity (L2-normalized)\n",
        "            print(f\"  {basename(image_paths[i])} ↔ {basename(image_paths[j])}  →  similarity: {sim:.4f}, distance: {1-sim:.4f}\")"
      ],
      "metadata": {
        "id": "eIEkqhDcj7m0"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model and transform only once\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "_model = mobilenet_v3_small(pretrained=True)\n",
        "_model = torch.nn.Sequential(*list(_model.children())[:-1])\n",
        "_model.to(device).eval()\n",
        "\n",
        "_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOPIw6zCziJd",
        "outputId": "00a3ff53-1e1d-46bf-8ace-c5f2d8406ce8"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset class for image paths\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, image_paths, transform):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.image_paths[idx]\n",
        "        image = Image.open(path).convert(\"RGB\")\n",
        "        return self.transform(image), path\n",
        "\n",
        "# Main grouping function\n",
        "def group_similar_images_opt(input_dir, eps=0.13, min_samples=2, batch_size=32, model=None, transform=None, use_gpu=True):\n",
        "    if model is None or transform is None:\n",
        "        raise ValueError(\"Model and transform must be provided for optimized usage.\")\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() and use_gpu else 'cpu')\n",
        "\n",
        "    # Collect valid image paths\n",
        "    valid_exts = ('.jpg', '.jpeg', '.png')\n",
        "    image_paths = [os.path.join(input_dir, f)\n",
        "                   for f in os.listdir(input_dir)\n",
        "                   if f.lower().endswith(valid_exts)]\n",
        "\n",
        "    if not image_paths:\n",
        "        print(\"No valid images found.\")\n",
        "        return\n",
        "\n",
        "    # Load dataset and dataloader\n",
        "    dataset = ImageDataset(image_paths, transform)\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    embeddings, final_paths = [], []\n",
        "\n",
        "    for batch_imgs, batch_paths in loader:\n",
        "        batch_imgs = batch_imgs.to(device)\n",
        "        with torch.no_grad():\n",
        "            batch_emb = model(batch_imgs).squeeze(-1).squeeze(-1).cpu().numpy()\n",
        "            batch_emb = batch_emb / np.linalg.norm(batch_emb, axis=1, keepdims=True)\n",
        "        embeddings.append(batch_emb)\n",
        "        final_paths.extend(batch_paths)\n",
        "\n",
        "    embeddings = np.vstack(embeddings).astype(np.float32)\n",
        "\n",
        "    # Compute cosine distance matrix\n",
        "    sim_matrix = cosine_similarity(embeddings)\n",
        "    dist_matrix = np.clip(1.0 - sim_matrix, 0.0, None)\n",
        "\n",
        "    # DBSCAN clustering\n",
        "    db = DBSCAN(eps=eps, min_samples=min_samples, metric='precomputed')\n",
        "    labels = db.fit_predict(dist_matrix)\n",
        "\n",
        "    label_counts = {label: list(labels).count(label) for label in set(labels)}\n",
        "\n",
        "    # Move images into cluster folders\n",
        "    cluster_id = 1\n",
        "    for label in set(labels):\n",
        "        if label == -1 or label_counts[label] < 2:\n",
        "            continue\n",
        "        group_dir = os.path.join(input_dir, f\"group_{cluster_id}\")\n",
        "        os.makedirs(group_dir, exist_ok=True)\n",
        "        for i, img_path in enumerate(final_paths):\n",
        "            if labels[i] == label:\n",
        "                shutil.move(img_path, os.path.join(group_dir, os.path.basename(img_path)))\n",
        "        cluster_id += 1\n",
        "\n",
        "    # print_cluster_similarities(image_paths, labels, embeddings)\n",
        "    print(f\"[✓] Grouped {len(final_paths)} images into {cluster_id - 1} clusters (no singleton folders).\")"
      ],
      "metadata": {
        "id": "QTDQg_GAhz54"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run clustering\n",
        "t1 = time.time()\n",
        "group_similar_images_opt(dir, eps=0.13, min_samples=2, batch_size=32, model=_model, transform=_transform)\n",
        "print(f\"Completed in {time.time() - t1:.2f} seconds.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aS9IRXTn1JSN",
        "outputId": "3d0b4fe4-1a20-44b3-fcc9-b96a4e11e6a0"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[✓] Grouped 48 images into 7 clusters (no singleton folders).\n",
            "Completed in 5.09 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def revert(parent_dir):\n",
        "    for root, dirs, files in os.walk(parent_dir, topdown=False):\n",
        "        if root == parent_dir:\n",
        "            continue  # Skip top-level dir\n",
        "\n",
        "        for file in files:\n",
        "            src_path = os.path.join(root, file)\n",
        "            dest_path = os.path.join(parent_dir, file)\n",
        "\n",
        "            # Handle filename conflict\n",
        "            if os.path.exists(dest_path):\n",
        "                base, ext = os.path.splitext(file)\n",
        "                i = 1\n",
        "                while True:\n",
        "                    new_name = f\"{base}_{i}{ext}\"\n",
        "                    new_dest = os.path.join(parent_dir, new_name)\n",
        "                    if not os.path.exists(new_dest):\n",
        "                        dest_path = new_dest\n",
        "                        break\n",
        "                    i += 1\n",
        "\n",
        "            os.rename(src_path, dest_path)\n",
        "\n",
        "        # Remove the now-empty subdirectory\n",
        "        try:\n",
        "            os.rmdir(root)\n",
        "        except OSError:\n",
        "            pass\n",
        "\n",
        "revert(dir)"
      ],
      "metadata": {
        "id": "ZFgKwBO2khyD"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2MZ5HdeZh2u6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}